{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52100a00-fdc2-4085-b2df-8f591fdc3068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, BatchNormalization, MaxPool2D, Flatten, Activation\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3a54a2-1d9a-4543-a2cb-db0bac029f62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = 'Brain Tumor/Training'\n",
    "test = 'Brain Tumor/Testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa1c604a-ad8c-44f0-960d-da27f7fe1950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = os.listdir(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57a3185-6730-4855-b094-e615666259fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meningioma_tumor', 'pituitary_tumor', 'no_tumor', 'glioma_tumor']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7d56073-31b6-4c12-8529-c58ca5914624",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added  = 100\n",
      "Images added  = 200\n",
      "Images added  = 300\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "c = 0\n",
    "for folder in classes:\n",
    "    if folder == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    for file in os.listdir(os.path.join(test, folder)):\n",
    "        # print(file)\n",
    "        # break\n",
    "        if file == '.ipynb_checkpoints':\n",
    "            continue\n",
    "        # c+=1\n",
    "        # if c<=2315:\n",
    "        #     continue\n",
    "        img = Image.open(os.path.join(os.path.join(test, folder), file))\n",
    "        img = np.array(img)\n",
    "        img = img/255.\n",
    "        img = np.resize(img,(128, 128, 3))\n",
    "        \n",
    "        if img is not None:\n",
    "            x.append(img)\n",
    "            y.append(classes.index(folder))\n",
    "            if len(x)%100 == 0:\n",
    "                print(\"Images added  =\", len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2840921d-68de-45c0-bf0b-8346558228c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('x', x)\n",
    "np.save('y', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0212692f-e029-4ce0-bb77-94fc3a2795d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2315"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154e9d5b-386b-48dd-8d6b-2a94a1e8425d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y = np.load('y.npy')\n",
    "x = np.load('x.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49be87b7-a95c-4ec8-bf8e-d19bd53fdbff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af5feb7-8584-4e4e-893b-8ed71a1d0335",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         ...,\n",
       "         [0.02745098, 0.02745098, 0.02745098],\n",
       "         [0.02745098, 0.02745098, 0.02745098],\n",
       "         [0.02745098, 0.02745098, 0.02745098]],\n",
       "\n",
       "        [[0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         ...,\n",
       "         [0.03137255, 0.03137255, 0.03137255],\n",
       "         [0.03137255, 0.03137255, 0.03137255],\n",
       "         [0.03137255, 0.03137255, 0.03137255]],\n",
       "\n",
       "        [[0.03137255, 0.03137255, 0.03137255],\n",
       "         [0.03137255, 0.03137255, 0.03137255],\n",
       "         [0.03137255, 0.03137255, 0.03137255],\n",
       "         ...,\n",
       "         [0.01568627, 0.01568627, 0.01568627],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.01176471, 0.01176471, 0.01176471]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.02745098, 0.02745098, 0.02745098],\n",
       "         [0.03137255, 0.03137255, 0.03137255],\n",
       "         [0.03529412, 0.03529412, 0.03529412],\n",
       "         ...,\n",
       "         [0.41568627, 0.41568627, 0.41568627],\n",
       "         [0.43137255, 0.43137255, 0.43137255],\n",
       "         [0.4627451 , 0.4627451 , 0.4627451 ]],\n",
       "\n",
       "        [[0.49411765, 0.49411765, 0.49411765],\n",
       "         [0.51764706, 0.51764706, 0.51764706],\n",
       "         [0.51372549, 0.51372549, 0.51372549],\n",
       "         ...,\n",
       "         [0.02745098, 0.02745098, 0.02745098],\n",
       "         [0.02745098, 0.02745098, 0.02745098],\n",
       "         [0.02745098, 0.02745098, 0.02745098]],\n",
       "\n",
       "        [[0.02745098, 0.02745098, 0.02745098],\n",
       "         [0.03137255, 0.03137255, 0.03137255],\n",
       "         [0.03137255, 0.03137255, 0.03137255],\n",
       "         ...,\n",
       "         [0.03529412, 0.03529412, 0.03529412],\n",
       "         [0.03921569, 0.03921569, 0.03921569],\n",
       "         [0.03921569, 0.03921569, 0.03921569]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.01568627, 0.01568627, 0.01568627],\n",
       "         ...,\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.01176471, 0.01176471, 0.01176471]],\n",
       "\n",
       "        [[0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         ...,\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.01176471, 0.01176471, 0.01176471]],\n",
       "\n",
       "        [[0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.68235294, 0.68235294, 0.68235294],\n",
       "         [0.66666667, 0.66666667, 0.66666667],\n",
       "         [0.64313725, 0.64313725, 0.64313725],\n",
       "         ...,\n",
       "         [0.48235294, 0.48235294, 0.48235294],\n",
       "         [0.38823529, 0.38823529, 0.38823529],\n",
       "         [0.49411765, 0.49411765, 0.49411765]],\n",
       "\n",
       "        [[0.58039216, 0.58039216, 0.58039216],\n",
       "         [0.59215686, 0.59215686, 0.59215686],\n",
       "         [0.60784314, 0.60784314, 0.60784314],\n",
       "         ...,\n",
       "         [0.04313725, 0.04313725, 0.04313725],\n",
       "         [0.02745098, 0.02745098, 0.02745098],\n",
       "         [0.02745098, 0.02745098, 0.02745098]],\n",
       "\n",
       "        [[0.02745098, 0.02745098, 0.02745098],\n",
       "         [0.02745098, 0.02745098, 0.02745098],\n",
       "         [0.02745098, 0.02745098, 0.02745098],\n",
       "         ...,\n",
       "         [0.69411765, 0.69411765, 0.69411765],\n",
       "         [0.72156863, 0.72156863, 0.72156863],\n",
       "         [0.67843137, 0.67843137, 0.67843137]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         ...,\n",
       "         [0.19607843, 0.19607843, 0.19607843],\n",
       "         [0.18431373, 0.18431373, 0.18431373],\n",
       "         [0.18431373, 0.18431373, 0.18431373]],\n",
       "\n",
       "        [[0.17254902, 0.17254902, 0.17254902],\n",
       "         [0.07843137, 0.07843137, 0.07843137],\n",
       "         [0.05490196, 0.05490196, 0.05490196],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.00392157]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.21176471, 0.21176471, 0.21176471],\n",
       "         [0.2       , 0.2       , 0.2       ],\n",
       "         [0.19215686, 0.19215686, 0.19215686],\n",
       "         ...,\n",
       "         [0.32156863, 0.32156863, 0.32156863],\n",
       "         [0.30588235, 0.30588235, 0.30588235],\n",
       "         [0.30196078, 0.30196078, 0.30196078]],\n",
       "\n",
       "        [[0.25882353, 0.25882353, 0.25882353],\n",
       "         [0.25490196, 0.25490196, 0.25490196],\n",
       "         [0.25098039, 0.25098039, 0.25098039],\n",
       "         ...,\n",
       "         [0.19607843, 0.19607843, 0.19607843],\n",
       "         [0.18823529, 0.18823529, 0.18823529],\n",
       "         [0.20784314, 0.20784314, 0.20784314]],\n",
       "\n",
       "        [[0.22745098, 0.22745098, 0.22745098],\n",
       "         [0.2745098 , 0.2745098 , 0.2745098 ],\n",
       "         [0.29803922, 0.29803922, 0.29803922],\n",
       "         ...,\n",
       "         [0.21176471, 0.21176471, 0.21176471],\n",
       "         [0.19607843, 0.19607843, 0.19607843],\n",
       "         [0.15294118, 0.15294118, 0.15294118]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         ...,\n",
       "         [0.03137255, 0.03137255, 0.03137255],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.01960784, 0.01960784, 0.01960784]],\n",
       "\n",
       "        [[0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         ...,\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02352941, 0.02352941, 0.02352941]],\n",
       "\n",
       "        [[0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.10980392, 0.10980392, 0.10980392],\n",
       "         [0.10980392, 0.10980392, 0.10980392],\n",
       "         [0.11372549, 0.11372549, 0.11372549],\n",
       "         ...,\n",
       "         [0.16862745, 0.16862745, 0.16862745],\n",
       "         [0.18431373, 0.18431373, 0.18431373],\n",
       "         [0.17254902, 0.17254902, 0.17254902]],\n",
       "\n",
       "        [[0.17647059, 0.17647059, 0.17647059],\n",
       "         [0.21960784, 0.21960784, 0.21960784],\n",
       "         [0.23921569, 0.23921569, 0.23921569],\n",
       "         ...,\n",
       "         [0.08627451, 0.08627451, 0.08627451],\n",
       "         [0.08627451, 0.08627451, 0.08627451],\n",
       "         [0.08235294, 0.08235294, 0.08235294]],\n",
       "\n",
       "        [[0.09411765, 0.09411765, 0.09411765],\n",
       "         [0.09411765, 0.09411765, 0.09411765],\n",
       "         [0.03921569, 0.03921569, 0.03921569],\n",
       "         ...,\n",
       "         [0.19607843, 0.19607843, 0.19607843],\n",
       "         [0.17254902, 0.17254902, 0.17254902],\n",
       "         [0.15294118, 0.15294118, 0.15294118]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c51a3cc-1a48-4e73-9805-095857d296de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.concatenate((x1, x2))\n",
    "y = np.concatenate((y1, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4a9b46b-c5d6-4747-a206-72af7e0a270f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.concatenate((x1, np.array(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9115d743-12e0-4970-a801-e3493be0b87c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.concatenate((y1, np.array(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab59024a-8ff0-4aa3-8ed4-7b844630f74e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3240, 128, 128, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e4a9572-8c79-48e4-8c24-d182e5a2eb6f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cccf8d9-eb3a-4622-9f05-d27bff080fce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test, x_cv, y_test, y_cv = train_test_split(x_test, y_test, test_size = 0.5, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5130cc4-982d-48b9-830c-17a325232ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 128, 128, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "444ee059-ac38-4dbe-b1a7-d8ed340e84eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('x_train', x_train)\n",
    "np.save('y_train', y_train)\n",
    "np.save('x_test', x_test)\n",
    "np.save('y_test', y_test)\n",
    "np.save('x_cv', x_cv)\n",
    "np.save('y_cv', y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b047f4-a315-4e78-867e-54b848de1887",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "x_cv = np.load('x_cv.npy')\n",
    "y_cv = np.load('y_cv.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8cd0dc0-45a5-4268-93c2-584f42e09ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2916, 128, 128, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a326f8-0bad-4458-ab83-c890e889b6f2",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4d4673db-9741-4a9f-b185-b8b25471eee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), input_shape = (128, 128, 3)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    \n",
    "    Conv2D(256, (3, 3)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    \n",
    "    Conv2D(32, (3, 3)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dropout(0.6),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    \n",
    "    Dense(4, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7af22a6e-611e-4ec9-8621-d3b3582ccfcd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_60 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 126, 126, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 61, 61, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 4, 4, 32)          73760     \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 481,252\n",
      "Trainable params: 480,228\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "09e41951-bf1f-4787-9a9c-a075d956052c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7c221b26-d682-4353-b177-ef6f9cb3a0ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cb = ModelCheckpoint(filepath = 'model.ckpt', save_best_only=True, save_weights_only=True, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1f756de6-ef8d-419f-858b-63b34e2c4a55",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7efda0226760>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('model2.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "55cc204e-4f51-412f-8472-192a88ddd647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3534 - accuracy: 0.8704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3534114956855774, 0.8703703880310059]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "23b55c38-675d-492a-a801-1dd44cf99d49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 9ms/step - loss: 0.2228 - accuracy: 0.9023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22284281253814697, 0.9022634029388428]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "87da19e6-36c3-4662-b73d-96cd3a54c2ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "92/92 [==============================] - 3s 26ms/step - loss: 1.2881 - accuracy: 0.4050 - val_loss: 1.3116 - val_accuracy: 0.3272\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.31156, saving model to model.ckpt\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 1.1331 - accuracy: 0.4798 - val_loss: 1.5951 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.31156\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 1.0758 - accuracy: 0.5106 - val_loss: 2.4466 - val_accuracy: 0.2716\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.31156\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 1.0478 - accuracy: 0.5285 - val_loss: 1.9087 - val_accuracy: 0.2778\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.31156\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 1.0063 - accuracy: 0.5436 - val_loss: 1.4878 - val_accuracy: 0.3827\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.31156\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 1.0110 - accuracy: 0.5405 - val_loss: 1.3220 - val_accuracy: 0.4198\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.31156\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 1.0246 - accuracy: 0.5357 - val_loss: 1.0514 - val_accuracy: 0.5679\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.31156 to 1.05137, saving model to model.ckpt\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.9708 - accuracy: 0.5703 - val_loss: 0.9400 - val_accuracy: 0.6049\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.05137 to 0.93998, saving model to model.ckpt\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.9622 - accuracy: 0.5655 - val_loss: 0.8985 - val_accuracy: 0.5802\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.93998 to 0.89848, saving model to model.ckpt\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.9643 - accuracy: 0.5665 - val_loss: 0.8965 - val_accuracy: 0.5802\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.89848 to 0.89647, saving model to model.ckpt\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.9354 - accuracy: 0.5754 - val_loss: 0.9338 - val_accuracy: 0.6111\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.89647\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.9173 - accuracy: 0.5816 - val_loss: 0.8222 - val_accuracy: 0.6049\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.89647 to 0.82224, saving model to model.ckpt\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.9423 - accuracy: 0.5744 - val_loss: 0.8643 - val_accuracy: 0.5617\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.82224\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.9182 - accuracy: 0.5806 - val_loss: 1.1644 - val_accuracy: 0.3704\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.82224\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.9034 - accuracy: 0.5926 - val_loss: 0.8134 - val_accuracy: 0.6481\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.82224 to 0.81343, saving model to model.ckpt\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.8908 - accuracy: 0.5977 - val_loss: 0.7794 - val_accuracy: 0.5988\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.81343 to 0.77939, saving model to model.ckpt\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.8850 - accuracy: 0.5926 - val_loss: 0.8386 - val_accuracy: 0.5864\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.77939\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.8859 - accuracy: 0.5998 - val_loss: 0.9116 - val_accuracy: 0.5679\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.77939\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.8900 - accuracy: 0.5885 - val_loss: 0.7651 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.77939 to 0.76511, saving model to model.ckpt\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.8596 - accuracy: 0.6080 - val_loss: 1.0165 - val_accuracy: 0.4568\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.76511\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.8747 - accuracy: 0.6036 - val_loss: 0.8233 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.76511\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.8516 - accuracy: 0.6022 - val_loss: 0.9274 - val_accuracy: 0.5864\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.76511\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.8488 - accuracy: 0.6152 - val_loss: 0.7470 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.76511 to 0.74701, saving model to model.ckpt\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.8257 - accuracy: 0.6211 - val_loss: 0.9080 - val_accuracy: 0.5802\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.74701\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.8521 - accuracy: 0.6091 - val_loss: 0.7710 - val_accuracy: 0.6481\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.74701\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.8000 - accuracy: 0.6358 - val_loss: 0.7502 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.74701\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.7998 - accuracy: 0.6416 - val_loss: 0.7039 - val_accuracy: 0.6914\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.74701 to 0.70388, saving model to model.ckpt\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.7848 - accuracy: 0.6440 - val_loss: 0.7029 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.70388 to 0.70288, saving model to model.ckpt\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.7941 - accuracy: 0.6355 - val_loss: 0.6964 - val_accuracy: 0.6914\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.70288 to 0.69637, saving model to model.ckpt\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.7940 - accuracy: 0.6447 - val_loss: 0.6780 - val_accuracy: 0.7222\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.69637 to 0.67796, saving model to model.ckpt\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.7435 - accuracy: 0.6725 - val_loss: 0.6350 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.67796 to 0.63504, saving model to model.ckpt\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.7707 - accuracy: 0.6670 - val_loss: 1.6520 - val_accuracy: 0.4198\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.63504\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.7627 - accuracy: 0.6632 - val_loss: 0.8257 - val_accuracy: 0.6420\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.63504\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.7448 - accuracy: 0.6766 - val_loss: 0.8095 - val_accuracy: 0.5679\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.63504\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.7342 - accuracy: 0.6804 - val_loss: 0.7283 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.63504\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.7040 - accuracy: 0.6958 - val_loss: 0.7357 - val_accuracy: 0.7160\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.63504\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.7091 - accuracy: 0.6924 - val_loss: 0.8786 - val_accuracy: 0.5679\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.63504\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.7075 - accuracy: 0.6910 - val_loss: 0.6987 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.63504\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.6961 - accuracy: 0.6955 - val_loss: 0.6413 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.63504\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.6666 - accuracy: 0.7099 - val_loss: 0.6705 - val_accuracy: 0.6728\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.63504\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.6594 - accuracy: 0.7130 - val_loss: 0.7405 - val_accuracy: 0.7222\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.63504\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.6626 - accuracy: 0.7215 - val_loss: 0.8284 - val_accuracy: 0.5617\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.63504\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.6594 - accuracy: 0.7236 - val_loss: 0.6273 - val_accuracy: 0.7531\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.63504 to 0.62730, saving model to model.ckpt\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.6495 - accuracy: 0.7130 - val_loss: 0.6336 - val_accuracy: 0.7222\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.62730\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.6082 - accuracy: 0.7500 - val_loss: 0.6775 - val_accuracy: 0.6852\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.62730\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.6198 - accuracy: 0.7315 - val_loss: 0.6507 - val_accuracy: 0.7222\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.62730\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.6000 - accuracy: 0.7401 - val_loss: 0.7210 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.62730\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.6191 - accuracy: 0.7332 - val_loss: 0.8835 - val_accuracy: 0.5494\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.62730\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.6157 - accuracy: 0.7353 - val_loss: 0.6011 - val_accuracy: 0.7840\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.62730 to 0.60112, saving model to model.ckpt\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5901 - accuracy: 0.7531 - val_loss: 1.1428 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.60112\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5862 - accuracy: 0.7531 - val_loss: 0.7361 - val_accuracy: 0.6049\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.60112\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5790 - accuracy: 0.7476 - val_loss: 0.5336 - val_accuracy: 0.7901\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.60112 to 0.53358, saving model to model.ckpt\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5887 - accuracy: 0.7510 - val_loss: 0.5872 - val_accuracy: 0.7531\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.53358\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5564 - accuracy: 0.7641 - val_loss: 0.5355 - val_accuracy: 0.7840\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.53358\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5759 - accuracy: 0.7527 - val_loss: 0.4963 - val_accuracy: 0.8210\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.53358 to 0.49631, saving model to model.ckpt\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5460 - accuracy: 0.7671 - val_loss: 0.5104 - val_accuracy: 0.8210\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.49631\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5259 - accuracy: 0.7771 - val_loss: 0.5687 - val_accuracy: 0.8086\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.49631\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5073 - accuracy: 0.7867 - val_loss: 0.4445 - val_accuracy: 0.8148\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.49631 to 0.44450, saving model to model.ckpt\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5856 - accuracy: 0.7548 - val_loss: 0.8807 - val_accuracy: 0.6543\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.44450\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5638 - accuracy: 0.7678 - val_loss: 0.5800 - val_accuracy: 0.7593\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.44450\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5209 - accuracy: 0.7737 - val_loss: 0.4975 - val_accuracy: 0.8025\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.44450\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4887 - accuracy: 0.7956 - val_loss: 0.5345 - val_accuracy: 0.7840\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.44450\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4878 - accuracy: 0.7980 - val_loss: 0.5772 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.44450\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4823 - accuracy: 0.7922 - val_loss: 0.8842 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.44450\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4745 - accuracy: 0.7990 - val_loss: 0.5169 - val_accuracy: 0.8025\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.44450\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4796 - accuracy: 0.8004 - val_loss: 0.9083 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.44450\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4565 - accuracy: 0.8066 - val_loss: 0.4523 - val_accuracy: 0.8086\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.44450\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4623 - accuracy: 0.8021 - val_loss: 1.8004 - val_accuracy: 0.3827\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.44450\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4546 - accuracy: 0.8124 - val_loss: 0.8069 - val_accuracy: 0.6049\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.44450\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4517 - accuracy: 0.8093 - val_loss: 0.6940 - val_accuracy: 0.7099\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.44450\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4471 - accuracy: 0.8162 - val_loss: 0.6992 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.44450\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.4562 - accuracy: 0.8090 - val_loss: 0.6289 - val_accuracy: 0.7284\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.44450\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4382 - accuracy: 0.8165 - val_loss: 0.5584 - val_accuracy: 0.7963\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.44450\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4353 - accuracy: 0.8131 - val_loss: 0.4901 - val_accuracy: 0.8148\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.44450\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4239 - accuracy: 0.8179 - val_loss: 0.6661 - val_accuracy: 0.7346\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.44450\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4882 - accuracy: 0.8021 - val_loss: 0.7096 - val_accuracy: 0.6914\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.44450\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4404 - accuracy: 0.8196 - val_loss: 0.9823 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.44450\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4590 - accuracy: 0.8121 - val_loss: 0.6219 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.44450\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.4116 - accuracy: 0.8278 - val_loss: 0.7491 - val_accuracy: 0.6790\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.44450\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4066 - accuracy: 0.8244 - val_loss: 0.5628 - val_accuracy: 0.7654\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.44450\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4145 - accuracy: 0.8265 - val_loss: 0.8289 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.44450\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.3762 - accuracy: 0.8416 - val_loss: 1.1164 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.44450\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.3960 - accuracy: 0.8333 - val_loss: 1.0919 - val_accuracy: 0.6049\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.44450\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4115 - accuracy: 0.8234 - val_loss: 1.7326 - val_accuracy: 0.5494\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.44450\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4026 - accuracy: 0.8278 - val_loss: 1.6809 - val_accuracy: 0.5617\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.44450\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.4098 - accuracy: 0.8241 - val_loss: 1.3024 - val_accuracy: 0.6049\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.44450\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4021 - accuracy: 0.8272 - val_loss: 0.8991 - val_accuracy: 0.6790\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.44450\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.3955 - accuracy: 0.8357 - val_loss: 0.9142 - val_accuracy: 0.5802\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.44450\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.3786 - accuracy: 0.8429 - val_loss: 0.6169 - val_accuracy: 0.7654\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.44450\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5065 - accuracy: 0.7949 - val_loss: 0.6164 - val_accuracy: 0.7531\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.44450\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.3975 - accuracy: 0.8254 - val_loss: 0.5593 - val_accuracy: 0.8086\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.44450\n",
      "Epoch 92/100\n",
      " 4/92 [>.............................] - ETA: 2s - loss: 0.3949 - accuracy: 0.8672"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-299cb9f87d85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 100, callbacks=[cb], validation_data=(x_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6017059c-0f57-49b5-ab47-b1ca652d3f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efd70f02d60>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.legend(['train_loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e72acb5d-af1d-42bb-a171-9dc94e786bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52b4f022-e15e-4c20-abe1-29e756989b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('base_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa950bc-493d-4b3c-bf18-5472fc609b11",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "63d50805-2359-4b51-9c86-b95eb0df861a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.load_model('model2.h5')\n",
    "model2 = tf.keras.models.load_model('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0e4477b1-ad5d-4679-8325-e1dfb4b90647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test = np.load('x_test.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a018051c-ad4c-4eb3-9c74-2d2ccccf5576",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3534 - accuracy: 0.8704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3534114956855774, 0.8703703880310059]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "99808f53-9e24-4de8-b956-5b23be75119d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3630 - accuracy: 0.8580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36303749680519104, 0.8580247163772583]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8c20b23d-6a26-4a44-b0de-54e3e75ebbfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_1 = model1.predict(x_test)\n",
    "pred_2 = model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "851ddd19-9067-4886-9aac-3e7ac17cddf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7c931dd1-4a1f-4faf-963f-3e4cf28ed6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_1 = np.argmax(pred_1, axis = -1)\n",
    "pred_2 = np.argmax(pred_2, axis = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5f1306b9-5002-4163-8ee6-f71780db8abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d27c8685-fa7e-4f57-9586-66d5c1e40c22",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cr1 = classification_report(y_test, pred_1)\n",
    "cr2 = classification_report(y_test, pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5f382add-225d-4a3f-a530-0d4cbf4cf0e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for model2.h5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78        46\n",
      "           1       0.80      0.98      0.88        41\n",
      "           2       0.87      0.93      0.90        29\n",
      "           3       0.90      0.78      0.84        46\n",
      "\n",
      "    accuracy                           0.85       162\n",
      "   macro avg       0.85      0.86      0.85       162\n",
      "weighted avg       0.85      0.85      0.84       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for model2.h5\")\n",
    "print(cr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "56360ccd-8afb-4317-b0f7-2af0bad0426d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for model1.h5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.79        46\n",
      "           1       0.86      0.93      0.89        41\n",
      "           2       0.93      0.97      0.95        29\n",
      "           3       0.84      0.83      0.84        46\n",
      "\n",
      "    accuracy                           0.86       162\n",
      "   macro avg       0.86      0.87      0.87       162\n",
      "weighted avg       0.86      0.86      0.86       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for model1.h5\")\n",
    "print(cr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2e21b170-e5f7-4c9d-86fe-d4f32a4ed84c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm1 = confusion_matrix(y_test, pred_1)\n",
    "cm2 = confusion_matrix(y_test, pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "74bd9350-bb4e-41b9-8723-f3d86437b95c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm1_dis = ConfusionMatrixDisplay(cm1)\n",
    "cm2_dis = ConfusionMatrixDisplay(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "52aff5df-28a8-4c19-800a-2fa695a0d17b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for model2.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f014c2829d0>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Confusion Matrix for model2.h5')\n",
    "cm1_dis.plot(include_values = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "098e742e-ac2e-4d20-a24f-545d09a9ef75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for model1.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f014c282a30>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Confusion Matrix for model1.h5')\n",
    "cm2_dis.plot(include_values = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e251f633-9f75-4689-be9f-78ad77803dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "346c68ab-7812-40cf-bec1-581cf7c80d95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f1_model1 = f1_score(y_test, pred_1, average = 'weighted')\n",
    "f1_model2 = f1_score(y_test, pred_2, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5a2d1c7c-4bf3-4f3f-b55b-958bec3760d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for model2.h5 = 0.8432691786385094\n",
      "F1 score for model1.h5 = 0.8566765738068312\n"
     ]
    }
   ],
   "source": [
    "print('F1 score for model2.h5 =', f1_model1)\n",
    "print('F1 score for model1.h5 =', f1_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576ec49e-a5d8-40bc-8947-62e52e3e5958",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d99be-0b79-438e-a1c8-a3a8a74250ae",
   "metadata": {},
   "source": [
    "The best model is stored in model1.h5"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-south-1:394103062818:image/tensorflow-2.6-gpu-py38-cu112-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
